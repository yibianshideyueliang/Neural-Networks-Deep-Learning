### 1、RNN ，LSTM，GRU模型介绍

###### 1.1 RNN（循环神经网络）

RNN是一种最基础的循环神经网络，用于处理序列数据。它通过将当前输入和前一时刻的隐藏状态（即记忆）结合起来，传递信息，从而捕捉到序列中的时序依赖性。

![img](https://i-blog.csdnimg.cn/blog_migrate/df72c977357f96d3e372979b6403b4b7.png)

但是RNN在处理长序列时会遇到梯度消失和梯度爆炸的问题，导致它无法有效捕捉长期依赖关系。

###### 1.2 LSTM（长短期记忆网络）

LSTM是一种特殊的RNN，它通过引入“门控”机制来解决标准RNN在长期依赖学习中的不足。LSTM网络使用了三个主要的门（输入门、遗忘门和输出门）来控制信息的流动和更新。LSTM的核心结构包括：①遗忘门决定丢弃前一时刻的多少记忆  ②输入门决定当前输入有多少信息应该被保存。 ③输出门决定下一时刻的隐藏状态（即记忆）应该传递多少。

![img](https://i-blog.csdnimg.cn/blog_migrate/c4751f800ebe179a04d700633eac49af.png)

LSTM通过这些门控机制避免了RNN的梯度消失问题，能更好地捕捉长期依赖。

###### 1.3 GRU（门控循环单元）

GRU是LSTM的一种变体，目的是进一步简化LSTM的结构，并保持相似的性能。GRU的主要创新在于它将LSTM中的“输入门”和“遗忘门”合并为一个“更新门”，从而减少了需要学习的参数数量。GRU的结构包括：①更新门决定当前的记忆应该保持多少。 ②重置门决定丢弃多少前一时刻的记忆。

![img](https://i-blog.csdnimg.cn/blog_migrate/4b9f7bf27bda033f46512179381445a7.png)

### 2、诗歌生成过程

#### tensorflow版本：

**数据处理**

1、读取文件

首先读取指定路径的文件 fileName。每一行的格式是以 :分割，后面的部分即为诗歌内容。

2、构建词汇表

统计每个词的出现频率，然后根据出现频率对词汇进行排序，并选取出现频率最高的词汇。

3、将文本转换为索引

诗歌中的每个字符都被映射为一个整数索引，word2id字典将每个词汇转换为对应的索引。得到的是一个由整数索引构成的诗歌列表。

4、生成 TensorFlow 数据集

通过 TensorFlow 的数据管道创建一个可用于训练的数据集，并进行必要的预处理，如批处理、填充和数据转换。

**模型结构**

1、嵌入层：将输入的词汇索引转换为词嵌入向量，嵌入维度为64。

2、RNN 单元：使用 SimpleRNNCell 来定义一个 RNN 层，输出的维度是 128。

3、RNN 层：利用 RNN 类封装了上面的 SimpleRNNCell，返回序列以便能传递到后续层。

4、全连接层：输出的维度是词汇表大小，用来生成每个时间步的预测。

**训练过程**

1、计算损失：在每个步骤中，通过模型的输出和真实标签计算损失。

2、计算梯度：使用 GradientTape记录梯度，计算损失对模型参数的梯度。

3、更新参数：使用优化器Adam更新模型参数。

4、循环训练：通过多个 epoch 和批次训练模型，不断调整参数以最小化损失。

**生成语句**

1、初始化当前 token：确定开始符号，将其映射到对应的词索引，并将其作为模型的第一个输入

2、循环生成 token：传入当前的 cur_token 和当前的状态 state，以获得下一个预测的 token 和更新后的状态。

3、生成词汇并返回：将 collect中的每个索引值（即生成的词汇索引）通过id2word 映射回词汇表中的单词，生成完整的句子。



#### pytorch版本：

**数据处理**

1、读取诗歌文件：从poems.txt文件中读取诗歌内容，并按行处理。

2、去除无效诗歌：过滤掉包含特殊字符的诗歌，或长度不符合要求的诗歌。

3、添加开始和结束标记：对每首诗歌，添加 start_token 和end_token，表示诗歌的开始和结束。

4、统计词频并构建词汇表：对诗歌中的所有字符进行统计，构建词到索引的映射和反向映射。

5、转换为索引形式：将每首诗中的字符转换为对应的索引，即每首诗对应的词汇索引序列。

**模型结构**

1、词嵌入层：将输入的词汇索引转换为词嵌入向量。

2、LSTM层：通过LSTM捕捉词汇之间的时序关系，具有两层LSTM堆叠。

3、全连接层：将LSTM输出的隐藏状态映射到词汇表的大小，用于生成词汇预测。

4、Softmax层：通过LogSoftmax计算每个词的预测概率。

**训练过程**

1、初始化模型：构建一个基于 LSTM 的 RNN 模型，模型的输入是词嵌入向量，输出是下一个词的预测。

2、定义优化器和损失函数：使用 RMSprop优化器和负对数似然损失函数NLLLoss进行模型训练。

3、训练模型

①在每个 epoch 中，生成批次数据并进行训练。

②对于每个批次，输入数据通过模型进行前向传播，计算损失，并反向传播更新模型参数。

③每 20 个批次保存一次模型。

##### **生成诗歌**

在训练完成后，使用训练好的模型生成诗歌：

1、加载已训练模型：加载保存的模型权重。

2、指定起始字符：根据输入的起始字符，从该字符开始生成诗歌。

3、逐步生成：

①将当前诗歌传入模型，得到下一个词的预测。

②通过模型输出的索引转换回词汇，逐步构建完整的诗歌。

③循环直到生成结束标记或生成的诗歌长度达到设定限制。

##### **打印生成的诗歌**

1、去掉开始和结束标记：只保留有效的诗歌内容。

2、按句子分割，并在每个句子后添加句号：使得打印出的诗歌更加工整。



### 3、诗歌生成结果

开头词汇是日 、 红 、 山 、 夜 、 湖、 海 、 月等词汇作为begin word

#### tensorflow版本：

![image-20250320222822722](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250320222822722.png)

![image-20250320222850456](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250320222850456.png)

![image-20250320222903989](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250320222903989.png)

#### pytorch版本：

训练截图：

运行时间较长，因此我将这个模型放到了服务器中运行

![image-20250321211050878](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250321211050878.png)

生成结果：

![image-20250321210450010](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250321210450010.png)

![image-20250321210506093](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250321210506093.png)

![image-20250321210532690](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250321210532690.png)

![image-20250321210738900](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250321210738900.png)

![image-20250321210801621](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250321210801621.png)

![image-20250321210814074](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250321210814074.png)

![image-20250321210825691](C:\Users\王泓烨\AppData\Roaming\Typora\typora-user-images\image-20250321210825691.png)

